{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SgPU0JiJhQUU"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize all to same shape and convert them to tensor\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Create Dataloaders and datasets for train and test set\n",
        "data_dir = 'https://drive.google.com/drive/folders/1jJ7TTKbpxXbXJEhy4mJ32Dd0G9W6JAfa?usp=share_link'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'test']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=128,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'test']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nZ0SWfohVlu",
        "outputId": "fa7c35a4-c32b-4b8c-fe71-ce0402edefa4"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFyNasTUiTMg",
        "outputId": "a95880d2-dd60-4607-d5cd-cb00aacd7b2f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bear', 'butterfly', 'camel', 'chimp', 'duck', 'elephant']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Resnet18 model\n",
        "model_conv = torchvision.models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS1RTYRoiEyy",
        "outputId": "b01d88de-13db-41e0-8775-616db0c2cffd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# total Batch shape\n",
        "# Each batch has 4 images, each of size 3*128*128\n",
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVF1mleRkGwA",
        "outputId": "18e12372-643c-4e0e-b044-452b56d9c3f0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output of resnet for a batch\n",
        "model_conv(inputs).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcW_7xVyih4z",
        "outputId": "f14a8fd9-9a67-485d-dea2-a58d6d40ccd5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture of resnet18\n",
        "list(model_conv.children())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNw-NpCOixZa",
        "outputId": "876fe531-fe7d-49ee-af36-cbbc59492dae"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
              " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
              " ReLU(inplace=True),\n",
              " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
              " Sequential(\n",
              "   (0): BasicBlock(\n",
              "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              "   (1): BasicBlock(\n",
              "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              " ),\n",
              " Sequential(\n",
              "   (0): BasicBlock(\n",
              "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (downsample): Sequential(\n",
              "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     )\n",
              "   )\n",
              "   (1): BasicBlock(\n",
              "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              " ),\n",
              " Sequential(\n",
              "   (0): BasicBlock(\n",
              "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (downsample): Sequential(\n",
              "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     )\n",
              "   )\n",
              "   (1): BasicBlock(\n",
              "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              " ),\n",
              " Sequential(\n",
              "   (0): BasicBlock(\n",
              "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (downsample): Sequential(\n",
              "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     )\n",
              "   )\n",
              "   (1): BasicBlock(\n",
              "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "     (relu): ReLU(inplace=True)\n",
              "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "   )\n",
              " ),\n",
              " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
              " Linear(in_features=512, out_features=1000, bias=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclude the final layer\n",
        "feature_ext = torch.nn.Sequential(*list(model_conv.children())[:-1])\n",
        "\n",
        "# Output of a batch after passing to feature_ext\n",
        "feature_ext(inputs).reshape((128,-1)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lv35x6ijRLo",
        "outputId": "fb3fadc7-67a1-40b7-9ab8-e31529425d69"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in feature_ext.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "0VtffIN3mX-U"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128"
      ],
      "metadata": {
        "id": "6RuLa7y0eEHC"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Formulate train and test dataset by getting feature vector of 512 size\n",
        "d = 512\n",
        "X_train = np.empty((0,d))\n",
        "Y_train = np.empty((0,1))\n",
        "X_test = np.empty((0,d))\n",
        "Y_test = np.empty((0,1))\n",
        "\n",
        "for inputs, labels in dataloaders['train']:\n",
        "  features = feature_ext(inputs).reshape(inputs.shape[0],-1)\n",
        "  X_train = np.append(X_train,features.numpy(),axis = 0)\n",
        "  Y_train = np.append(Y_train,labels.numpy().reshape(-1,1),axis = 0)\n",
        "\n",
        "for inputs, labels in dataloaders['test']:\n",
        "  features = feature_ext(inputs).reshape(inputs.shape[0],-1)\n",
        "  X_test = np.append(X_test,features.numpy(),axis = 0)\n",
        "  Y_test = np.append(Y_test,labels.numpy().reshape(-1,1),axis = 0)"
      ],
      "metadata": {
        "id": "eg3hm4ickO76"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXsaZuIoer2i",
        "outputId": "d7fefa8a-e448-4dd3-e1b1-8e7324f0371c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([120, 3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train shape -- {X_train.shape}\")\n",
        "print(f\"Y_train shape -- {Y_train.shape}\")\n",
        "print(f\"X_test shape -- {X_test.shape}\")\n",
        "print(f\"X_test shape -- {Y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCmePw8vkdwI",
        "outputId": "f38dcf14-d17e-4db3-a169-fb473a46ac58"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape -- (532, 512)\n",
            "Y_train shape -- (532, 1)\n",
            "X_test shape -- (120, 512)\n",
            "X_test shape -- (120, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-NN classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=5)\n",
        "neigh.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_OP0yR-uocN",
        "outputId": "efd5c9ee-7f9e-4c8e-bb98-525cfc118832"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/neighbors/_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigns a vector to a dominating class among K-Nearest Neighbours\n",
        "predictions = neigh.predict(X_test)"
      ],
      "metadata": {
        "id": "PaNa5GqcwJ9d"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, predictions, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b2_GbtJwXNx",
        "outputId": "2ee2d08c-5ece-4f2a-9e38-11f33ec72cfc"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        bear       0.90      0.95      0.93        20\n",
            "   butterfly       0.95      1.00      0.98        20\n",
            "       camel       0.94      0.85      0.89        20\n",
            "       chimp       0.95      0.95      0.95        20\n",
            "        duck       1.00      0.90      0.95        20\n",
            "    elephant       0.91      1.00      0.95        20\n",
            "\n",
            "    accuracy                           0.94       120\n",
            "   macro avg       0.94      0.94      0.94       120\n",
            "weighted avg       0.94      0.94      0.94       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy as fraction of correctly classfied test images\n",
        "sum(predictions.reshape(-1,1)==Y_test).astype(int)/Y_test.shape[0]"
      ],
      "metadata": {
        "id": "qjHRwoXOweHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3829ee2-6102-4cf9-eeba-6d5a3843cb05"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.94166667])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3hKijtXVclEj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}